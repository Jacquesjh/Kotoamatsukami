{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pickle\n",
    "import time\n",
    "from typing import Callable, Dict, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from kotoamatsukami import HandDetector\n",
    "\n",
    "\n",
    "\n",
    "supported_windows = [\"edge\", \"powerpoint\"]\n",
    "\n",
    "\n",
    "def load_model() -> RandomForestClassifier:\n",
    "    with open(\"models/decision_tree\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_gesture_labes() -> Dict[int, str]:\n",
    "    labels = {\n",
    "        0: \"click\",\n",
    "        1: \"closed\",\n",
    "        2: \"down\",\n",
    "        3: \"mouse_tracking\",\n",
    "        4: \"negative_closed\",\n",
    "        5: \"negative_mouse_tracking\",\n",
    "        6: \"negative_side\",\n",
    "        7: \"negative_up\",\n",
    "        8: \"side\",\n",
    "        9: \"up\"\n",
    "    }\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def mouse_tracking_command(x_offset: int, y_offset: int) -> None:\n",
    "    pyautogui.moveRel(xOffset=x_offset, yOffset=y_offset)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "\n",
    "def closed_command(hand_type: str) -> None:\n",
    "    if hand_type == \"Right\":\n",
    "        pyautogui.hotkey(\"playpause\")\n",
    "        time.sleep(0.1)\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "def down_command(hand_type: str) -> None:\n",
    "    if hand_type == \"Right\":\n",
    "        pyautogui.click()\n",
    "        time.sleep(0.25)\n",
    "        pyautogui.hotkey(\"pgdn\")\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "def up_command(hand_type: str) -> None:\n",
    "    if hand_type == \"Right\":\n",
    "        pyautogui.click()\n",
    "        time.sleep(0.25)\n",
    "        pyautogui.hotkey(\"pgup\")\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "def side_command(hand_type: str) -> None:\n",
    "    # pyautogui.click()\n",
    "    # time.sleep(0.25)\n",
    "    active_window_full_name = pyautogui.getActiveWindowTitle()\n",
    "    names = active_window_full_name.lower().split()\n",
    "\n",
    "    if \"edge\" in names:\n",
    "        if hand_type == \"Right\":\n",
    "            pyautogui.hotkey(\"browserforward\")\n",
    "\n",
    "        else:\n",
    "            pyautogui.hotkey(\"browserback\")\n",
    "\n",
    "    if \"powerpoint\" in names:\n",
    "        if hand_type == \"Right\":\n",
    "            pyautogui.hotkey(\"down\")\n",
    "\n",
    "        else:\n",
    "            pyautogui.hotkey(\"up\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "def null_command(hand_type: str) -> None:\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_commands_table() -> Dict[int, Callable]:\n",
    "    commands_table = {\n",
    "        1: closed_command,\n",
    "        2: up_command,\n",
    "        8: side_command,\n",
    "        9: down_command\n",
    "    }\n",
    "\n",
    "    return commands_table\n",
    "\n",
    "\n",
    "def get_mouse_move_offset(hand: dict, previous_x: int, previous_y: int) -> Tuple[float, float]:\n",
    "    current_x = hand[\"pos_x\"]\n",
    "    current_y = hand[\"pos_y\"]\n",
    "\n",
    "    x_coef = -1920/1280         # Ta negativo para espelhar a imagem\n",
    "    y_coef = 1080/720\n",
    "\n",
    "    x_offset = (current_x - previous_x)*x_coef\n",
    "    y_offset = (current_y - previous_y)*y_coef\n",
    "\n",
    "    return x_offset, y_offset\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"Starting!!!\")\n",
    "\n",
    "    min_probability = 0.9\n",
    "    commands_table  = get_commands_table()\n",
    "\n",
    "    stream = cv2.VideoCapture(0)\n",
    "    hand_detector = HandDetector(max_hands=1, detection_con=0.9, normalize=True)\n",
    "\n",
    "    labels = get_gesture_labes()\n",
    "    model  = load_model()\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    previous_x = None\n",
    "    previous_y = None\n",
    "\n",
    "    was_clicking = False\n",
    "\n",
    "    while True:\n",
    "        clicking = False\n",
    "\n",
    "        _grabbed, frame = stream.read()\n",
    "\n",
    "        if cv2.waitKey(1) == ord(\"x\"):\n",
    "            break\n",
    "\n",
    "        hands, image = hand_detector.find_hands(image=frame, draw_box=True, draw_marks=True)\n",
    "\n",
    "        if len(hands) != 0:\n",
    "            for hand in hands:\n",
    "                landmark = hand[\"landmarks\"]\n",
    "\n",
    "                prediction = model.predict_proba(np.array(landmark).reshape(1, 42))\n",
    "\n",
    "                if prediction.max() >= min_probability:\n",
    "                    pred = prediction.argmax()\n",
    "\n",
    "                    if pred == 0:\n",
    "                        clicking = True\n",
    "\n",
    "                        if was_clicking is False:\n",
    "                            pyautogui.mouseDown()\n",
    "\n",
    "                    else:\n",
    "                        clicking = False\n",
    "\n",
    "                    if pred in [0, 3] and hand[\"type\"] == \"Right\":\n",
    "                        if previous_x is None:\n",
    "                            previous_x = hand[\"pos_x\"]\n",
    "                            previous_y = hand[\"pos_y\"]\n",
    "\n",
    "                        x_offset, y_offset = get_mouse_move_offset(hand=hand, previous_x=previous_x, previous_y=previous_y)\n",
    "                        mouse_tracking_command(x_offset=x_offset, y_offset=y_offset)\n",
    "\n",
    "                    if pred == 6 and hand[\"type\"] == \"Left\":\n",
    "                        pred = 8\n",
    "\n",
    "                    print(f\"Caught the {labels.get(prediction.argmax())} gesture - {i}\")\n",
    "\n",
    "                    i += 1\n",
    "\n",
    "                    command = commands_table.get(pred, null_command)\n",
    "\n",
    "                    command(hand_type=hand[\"type\"])\n",
    "\n",
    "                previous_x = hand[\"pos_x\"]\n",
    "                previous_y = hand[\"pos_y\"]\n",
    "\n",
    "        if was_clicking is False and clicking is True:\n",
    "            was_clicking = True\n",
    "\n",
    "        if was_clicking is True and clicking is False:\n",
    "            was_clicking = False\n",
    "            pyautogui.mouseUp()\n",
    "\n",
    "    \n",
    "        cv2.imshow(\"Video\", image)\n",
    "        \n",
    "    stream.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!!!\n",
      "Caught the mouse_tracking gesture - 0\n",
      "Caught the mouse_tracking gesture - 1\n",
      "Caught the mouse_tracking gesture - 2\n",
      "Caught the mouse_tracking gesture - 3\n",
      "Caught the mouse_tracking gesture - 4\n",
      "Caught the mouse_tracking gesture - 5\n",
      "Caught the mouse_tracking gesture - 6\n",
      "Caught the mouse_tracking gesture - 7\n",
      "Caught the mouse_tracking gesture - 8\n",
      "Caught the mouse_tracking gesture - 9\n",
      "Caught the mouse_tracking gesture - 10\n",
      "Caught the mouse_tracking gesture - 11\n",
      "Caught the mouse_tracking gesture - 12\n",
      "Caught the mouse_tracking gesture - 13\n",
      "Caught the mouse_tracking gesture - 14\n",
      "Caught the mouse_tracking gesture - 15\n",
      "Caught the mouse_tracking gesture - 16\n",
      "Caught the mouse_tracking gesture - 17\n",
      "Caught the mouse_tracking gesture - 18\n",
      "Caught the mouse_tracking gesture - 19\n",
      "Caught the mouse_tracking gesture - 20\n",
      "Caught the mouse_tracking gesture - 21\n",
      "Caught the mouse_tracking gesture - 22\n",
      "Caught the mouse_tracking gesture - 23\n",
      "Caught the mouse_tracking gesture - 24\n",
      "Caught the mouse_tracking gesture - 25\n",
      "Caught the mouse_tracking gesture - 26\n",
      "Caught the mouse_tracking gesture - 27\n",
      "Caught the mouse_tracking gesture - 28\n",
      "Caught the mouse_tracking gesture - 29\n",
      "Caught the mouse_tracking gesture - 30\n",
      "Caught the mouse_tracking gesture - 31\n",
      "Caught the mouse_tracking gesture - 32\n",
      "Caught the mouse_tracking gesture - 33\n",
      "Caught the mouse_tracking gesture - 34\n",
      "Caught the mouse_tracking gesture - 35\n",
      "Caught the mouse_tracking gesture - 36\n",
      "Caught the mouse_tracking gesture - 37\n",
      "Caught the mouse_tracking gesture - 38\n",
      "Caught the mouse_tracking gesture - 39\n",
      "Caught the mouse_tracking gesture - 40\n",
      "Caught the mouse_tracking gesture - 41\n",
      "Caught the mouse_tracking gesture - 42\n",
      "Caught the mouse_tracking gesture - 43\n",
      "Caught the mouse_tracking gesture - 44\n",
      "Caught the mouse_tracking gesture - 45\n",
      "Caught the mouse_tracking gesture - 46\n",
      "Caught the mouse_tracking gesture - 47\n",
      "Caught the mouse_tracking gesture - 48\n",
      "Caught the mouse_tracking gesture - 49\n",
      "Caught the mouse_tracking gesture - 50\n",
      "Caught the mouse_tracking gesture - 51\n",
      "Caught the click gesture - 52\n",
      "Caught the click gesture - 53\n",
      "Caught the click gesture - 54\n",
      "Caught the click gesture - 55\n",
      "Caught the click gesture - 56\n",
      "Caught the click gesture - 57\n",
      "Caught the click gesture - 58\n",
      "Caught the click gesture - 59\n",
      "Caught the click gesture - 60\n",
      "Caught the click gesture - 61\n",
      "Caught the click gesture - 62\n",
      "Caught the click gesture - 63\n",
      "Caught the click gesture - 64\n",
      "Caught the click gesture - 65\n",
      "Caught the click gesture - 66\n",
      "Caught the click gesture - 67\n",
      "Caught the click gesture - 68\n",
      "Caught the click gesture - 69\n",
      "Caught the click gesture - 70\n",
      "Caught the click gesture - 71\n",
      "Caught the click gesture - 72\n",
      "Caught the click gesture - 73\n",
      "Caught the click gesture - 74\n",
      "Caught the click gesture - 75\n",
      "Caught the click gesture - 76\n",
      "Caught the click gesture - 77\n",
      "Caught the click gesture - 78\n",
      "Caught the click gesture - 79\n",
      "Caught the click gesture - 80\n",
      "Caught the click gesture - 81\n",
      "Caught the click gesture - 82\n",
      "Caught the click gesture - 83\n",
      "Caught the click gesture - 84\n",
      "Caught the click gesture - 85\n",
      "Caught the click gesture - 86\n",
      "Caught the mouse_tracking gesture - 87\n",
      "Caught the mouse_tracking gesture - 88\n",
      "Caught the mouse_tracking gesture - 89\n",
      "Caught the click gesture - 90\n",
      "Caught the click gesture - 91\n",
      "Caught the click gesture - 92\n",
      "Caught the click gesture - 93\n",
      "Caught the click gesture - 94\n",
      "Caught the click gesture - 95\n",
      "Caught the click gesture - 96\n",
      "Caught the click gesture - 97\n",
      "Caught the click gesture - 98\n",
      "Caught the click gesture - 99\n",
      "Caught the mouse_tracking gesture - 100\n",
      "Caught the mouse_tracking gesture - 101\n",
      "Caught the mouse_tracking gesture - 102\n",
      "Caught the click gesture - 103\n",
      "Caught the click gesture - 104\n",
      "Caught the click gesture - 105\n",
      "Caught the click gesture - 106\n",
      "Caught the click gesture - 107\n",
      "Caught the click gesture - 108\n",
      "Caught the click gesture - 109\n",
      "Caught the click gesture - 110\n",
      "Caught the click gesture - 111\n",
      "Caught the click gesture - 112\n",
      "Caught the click gesture - 113\n",
      "Caught the click gesture - 114\n",
      "Caught the click gesture - 115\n",
      "Caught the click gesture - 116\n",
      "Caught the click gesture - 117\n",
      "Caught the click gesture - 118\n",
      "Caught the click gesture - 119\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('kotoamatsukami-Hq7iVI3N-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36e694ef7c3cc3ea9fcbe33622def963131e2f8f250b2d91c3914ff84d9031bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
