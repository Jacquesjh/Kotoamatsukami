{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/randomized/train_data\", \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "train_features = train_data[0]\n",
    "train_targets  = train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/randomized/val_data\", \"rb\") as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "val_features = val_data[0]\n",
    "val_targets  = val_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/randomized/test_data\", \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "test_features = test_data[0]\n",
    "test_targets  = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_train(unshaped: list) -> np.array:\n",
    "    shaped = np.array([np.array(sample).reshape(-1, 1) for sample in unshaped])\n",
    "    shaped = shaped.reshape(shaped.shape[0], shaped.shape[1])\n",
    "\n",
    "    return shaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaped_train_features = reshape_to_train(unshaped=train_features)\n",
    "shaped_val_features   = reshape_to_train(unshaped=val_features)\n",
    "shaped_test_features  = reshape_to_train(unshaped=test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimzing the Model over the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "\n",
    "hps = {i: kernel for i, kernel in enumerate(kernels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4, 4, 6, 1, 2, 1, 9, 1, 8, 6, 5, 2, 4, 2, 8, 9, 4, 8, 8, 8, 1,\n",
       "       4, 6, 1, 4, 8, 6, 7, 1, 0, 9, 2, 5, 1, 4, 8, 4, 1, 0, 4, 4, 2, 1,\n",
       "       9, 2, 4, 0, 0, 1, 1, 4, 8, 4, 1, 8, 1, 9, 1, 3, 8, 7, 5, 6, 0, 0,\n",
       "       5, 4, 4, 4, 4, 0, 1, 6, 2, 8, 1, 4, 4, 8, 1, 1, 1, 0, 6, 4, 4, 7,\n",
       "       1, 4, 1, 1, 8, 7, 6, 1, 5, 1, 9, 4, 7, 0, 4, 0, 4, 6, 4, 1, 1, 8,\n",
       "       4, 1, 1, 1, 7, 0, 5, 1, 0, 1, 8, 0, 0, 8, 2, 1, 1, 4, 8, 4, 8, 1,\n",
       "       2, 8, 0, 8, 4, 4, 4, 2, 4, 0, 4, 1, 7, 8, 1, 4, 2, 4, 4, 5, 4, 9,\n",
       "       0, 8, 4, 8, 5, 3, 1, 4, 4, 0, 1, 1, 6, 6, 4, 2, 4, 1, 4, 8, 6, 6,\n",
       "       8, 4, 4, 8, 6, 1, 1, 6, 6, 8, 1, 4, 8, 6, 4, 0, 7, 6, 1, 1, 6, 0,\n",
       "       4, 6, 1, 1, 6, 1, 7, 5, 4, 4, 4, 0, 4, 0, 7, 4, 1, 1, 7, 9, 1, 1,\n",
       "       0, 8, 4, 4, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  accuracy F1-score\n",
      "0    98.22    97.74\n",
      "1    97.78    97.38\n",
      "2    98.22    98.12\n",
      "3     64.0    54.14\n",
      "{0: 'linear', 1: 'poly', 2: 'rbf', 3: 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"accuracy\", \"F1-score\"], index=[i for i in range(len(hps))])\n",
    "\n",
    "for index, hp in hps.items():\n",
    "    kernel = hp\n",
    "    nb_model = SVC(kernel=kernel)\n",
    "\n",
    "    nb_model.fit(X=shaped_train_features, y=train_targets)\n",
    "\n",
    "    predictions = nb_model.predict(shaped_val_features)\n",
    "    acc = accuracy_score(y_true=val_targets, y_pred=new)\n",
    "    acc = round(acc*100, 2)\n",
    "\n",
    "    f1score = f1_score(y_true=val_targets, y_pred=new, average=\"macro\")\n",
    "    f1score = round(f1score*100, 2)\n",
    "\n",
    "    df[\"accuracy\"].loc[index] = acc\n",
    "    df[\"F1-score\"].loc[index] = f1score\n",
    "\n",
    "print(df)\n",
    "\n",
    "print(hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(shrinking=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC(kernel=\"rbf\", shrinking=False)\n",
    "\n",
    "svc_model.fit(shaped_train_features, train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svc_model.predict(shaped_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 97.42%\n",
      "The F1-Score is 88.6%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1125, 225]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12308/4251339328.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"The F1-Score is {f1}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredicions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredicions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joao\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kotoamatsukami-T53X9OZe-py3.8\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2108\u001b[0m     \"\"\"\n\u001b[0;32m   2109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2110\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2112\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joao\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kotoamatsukami-T53X9OZe-py3.8\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joao\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kotoamatsukami-T53X9OZe-py3.8\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1125, 225]"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_true=test_targets, y_pred=predictions)\n",
    "accuracy = round(acc*100, 2)\n",
    "\n",
    "print(f\"The accuracy is {accuracy}%\")\n",
    "\n",
    "f1 = f1_score(y_true=test_targets, y_pred=predictions, average=\"macro\")\n",
    "f1 = round(f1*100, 2)\n",
    "\n",
    "print(f\"The F1-Score is {f1}%\")\n",
    "\n",
    "print(classification_report(y_true=test_targets, y_pred=predicions, digits=4))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=test_targets, y_pred=predicions)\n",
    "px.imshow(conf_matrix, color_continuous_scale=\"blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/svc_model\", \"wb\") as f:\n",
    "    pickle.dump(svc_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('kotoamatsukami-T53X9OZe-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a51161d7ba46dd3dbd9fc8c6bd348fb23b578d1cf3ae09598f24443a1428645a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
